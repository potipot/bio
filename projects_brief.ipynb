{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pawel Potrykus \n",
    "## Projects and experience brief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fever detector\n",
    "*single-class multi-target*\n",
    "\n",
    "A computer vision project for detecting faces in infrared images. The idea was to run it on a mobile device with dedicated infrared camera (odroid + seektherm) so model efficiency was important. **I was responisble for the full workflow of product development: research, dataset preparation, model training, c++ backend creation, deployment** \n",
    "### dataset\n",
    "a mix of infrared datasets found online, rgb images converted to grayscale and manually gathered infrared photographs of human faces. Its a single class (face) with multiple possible targets in an image\n",
    "### model \n",
    "here an exisiting model and pytorch training workflow was used [link](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) the model is based on RetinaFace\n",
    "### deployment\n",
    "1. the model was deployed to a mobile device using a set of conversion methods:pytorch pth > onnx > onnx_simplifier\n",
    "2. the model was installed in production in c++ with opencv-dnn environment for increased efficiency \n",
    "\n",
    "<img src=\"https://i.imgur.com/bW1Dr1Y.gif\" width=\"500\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted items detection (undergoing)\n",
    "*multi-class multi-target*\n",
    "\n",
    "The goal is to detect objects with restricted customs requirements (cigarettes, liquids, sharp objects, food products). The model is designed to work on mobile phones as an asset of an android app.\n",
    "### dataset\n",
    "the dataset was created using a synthetic generator: by mixing 8000 background images and 13000 manually labelled target item masks. It contains 20 classes and 0-5 objects per image\n",
    "### model\n",
    "the model uses a RetinaNet architecture with different encoders (resnet{18, 34, 50}) to find the best ratio between detection performance and inference time\n",
    "### metrics\n",
    "mean average precision (mAP) is used as a metric of detection performance. its values are monitored for each class and for a dataset as a whole\n",
    "<img src=\"https://i.imgur.com/4Al3ivy.png\" width=\"500\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition (undergoing)\n",
    "*automatic speech recognition, speech-to-text*\n",
    "\n",
    "Polish language speech recognition. I work with 1700h of loosely labelled speech samples. I created a framework for raw audio processing based on [fastai_audio](https://github.com/fastaudio/fastai_audio) but have significantly extended it.\n",
    "\n",
    "Workflow summary:\n",
    "- read raw audio samples, \n",
    "- create mel-spectrograms,\n",
    "- cache them for faster retrieval, \n",
    "- data augmentation based on [SpecAugment](https://arxiv.org/abs/1904.08779)\n",
    "\n",
    "### dataset\n",
    "the dataset is a mix of open datasets: clarin_pl, mozilla common voice and company gathered samples\n",
    "### model\n",
    "[Deepspeech 2](https://arxiv.org/abs/1512.02595) based architecture: convolutional + recurrent blocks\n",
    "### metrics\n",
    "main used metrics in ASR are WER and CER. I managed to reach 0.31 wer with my dataset and approach (SOTA for polish langauge is ~0.20, lower is better)\n",
    "<img src=\"https://i.imgur.com/ZO2jWep.jpg\" height=\"500\" align=\"center\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
